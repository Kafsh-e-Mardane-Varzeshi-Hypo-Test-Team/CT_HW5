<configuration>
	<property>
		<name>dfs.nameservices</name>
		<value>hdfs-cluster</value>
	</property>

	<property>
		<name>dfs.ha.namenodes.hdfs-cluster</name>
		<value>nn1,nn2</value>
	</property>

	<property>
		<name>dfs.namenode.rpc-address.hdfs-cluster.nn1</name>
		<value>namenode1:8020</value>
	</property>
	<property>
		<name>dfs.namenode.rpc-address.hdfs-cluster.nn2</name>
		<value>namenode2:8020</value>
	</property>

	<property>
		<name>dfs.namenode.http-address.hdfs-cluster.nn1</name>
		<value>namenode1:9870</value>
	</property>
	<property>
		<name>dfs.namenode.http-address.hdfs-cluster.nn2</name>
		<value>namenode2:9870</value>
	</property>

	<property>
    	<name>dfs.namenode.name.dir</name>
    	<value>file:///hadoop/dfs/name</value>
 	 </property>
  	<property>
   		<name>dfs.datanode.data.dir</name>
    	<value>file:///hadoop/dfs/data</value>
	</property>

	<property>
		<name>dfs.namenode.shared.edits.dir</name>
		<value>qjournal://journalnode:8485/hdfs-cluster</value>
	</property>

	<property>
		<name>dfs.client.failover.proxy.provider.hdfs-cluster</name>
		<value>org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider</value>
	</property>

	<property>
		<name>dfs.ha.automatic-failover.enabled</name>
		<value>true</value>
	</property>

	<property>
  		<name>dfs.journalnode.edits.dir</name>
  		<value>/hadoop/dfs/journal</value>
	</property>

</configuration>

